{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOMS I COGNOMS: Maria Pérez i Quim Lagunas\n",
    "\n",
    "GRUP: B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificació\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest quart lliurament es programarà un classificador, que donat un tweet el categoritzarà en una de les possibles classes. En aquesta ocasió, implementareu un classificador amb tweets de cyber bullying.\n",
    "\n",
    "\n",
    "**Què s’ha de fer?**\n",
    "\n",
    "Volem classificar tweets segons a quin tipus de cyber bullying pertanyen. Així doncs, a partir de tots els tweets que tenim, crearem un vector de característiques que ens descrigui cadascun. Finalment desenvoluparem un classificador probabilístic del tipus Naive Bayes que ens permeti identificar a quina classe de cyber bullying pertany un tweet donat segons les característiques triades.\n",
    "\n",
    "\n",
    "**Quina és la idea del sistema de classificació que s’ha de desenvolupar?**\n",
    "\n",
    "El classificador és un concepte de l'aprenentatge automàtic supervisat. L'objectiu del classificador és donat un vector de característiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "\n",
    "El procés de classificació consta de dues parts: \n",
    "(a) el procés d'aprenentatge i \n",
    "(b) el procés d'explotació o testeig. \n",
    "El procés d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ són les característiques, usualment nombres reals, i $y$ és la categoria a la que pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servirà per trobar una funció $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el procés de testeig aplica la funció $h(x)$ apresa a l'entrenament a una nova descripció per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificació i llenguatge natural**\n",
    "\n",
    "La descripció dels exemples en característiques és el punt més crític de tot sistema d'aprenentatge automàtic. \n",
    "Una de les representacions més simples per tal de descriure un text és la representació *bag-of-words*.\n",
    "Aquesta representació converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versió alternativa d'aquest procés pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ Durant la pràctica, solament es podran fer servir les següents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A més de les que ja es troben presents en la 1a cel·la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "Això no implica però que els hàgiu de fer servir. És a dir, que la funció tingui un paràmetre anomenat `df` no implica que l'hàgiu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica que serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posarà en el pydoc de la funció), `df` sempre serà indicatiu del `Pandas.DataFrame` de les dades. Durant els testos, els paràmetres (i específicament `df`) no contindran les mateixes dades que en aquest notebook, si bé si seran del mateix tipus! Per tant, no us refieu de què tinguin, per exemple, el mateix nombre de files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Més informació del dataset\n",
    "\n",
    "El 15 d'Abril de 2020, UNICEF va llançar una alarma com a resposta de l'augment de risc de cyberbullying durant la pandèmia COVID-19. Les estadístiques són prou alarmants: un 36.5% dels estudiants de l'escola fins a l'institut s'han sentit víctimes del cyberbullying i un 87% l'han observat, amb efectes que van des d'una disminució de resultats acadèmics fins a pensaments suïcides.\n",
    "\n",
    "Amb l'objectiu d'ajudar a l'analisis de la situació, s'ha construit un dataset que conté més de 47000 tweets etiquetats d'acord amb la classe de cyberbullying que s'està donant:\n",
    "\n",
    "1. Age;\n",
    "2. Ethnicity;\n",
    "3. Gender;\n",
    "4. Religion;\n",
    "5. Other type of cyberbullying;\n",
    "6. Not cyberbullying\n",
    "\n",
    "Les dades han estat balancejades per tal de contenir aproximadament 8000 mostres de cada classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llegim dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cyberbullying_tweets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion               7998\n",
       "age                    7992\n",
       "gender                 7973\n",
       "ethnicity              7961\n",
       "not_cyberbullying      7945\n",
       "other_cyberbullying    7823\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividim dataset\n",
    "\n",
    "Dividim els tweets en un conjunt d'entrenament, *train*, i en un conjunt de validació, *test*, per tal de poder entrenar i validar el nostre model de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_tweets_train, df_tweets_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com les dades estaven balancejades originalment, podem observar que la distribució de cadascuna de les classes es manté:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    6399\n",
       "ethnicity              6375\n",
       "gender                 6372\n",
       "religion               6368\n",
       "not_cyberbullying      6357\n",
       "other_cyberbullying    6282\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion               1630\n",
       "gender                 1601\n",
       "age                    1593\n",
       "not_cyberbullying      1588\n",
       "ethnicity              1586\n",
       "other_cyberbullying    1541\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_test['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementació\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. Anàlisis de dades: Informació bàsica sobre els tweets\n",
    "2. Processament de les dades: Creació d'un vector de característiques a partir dels tweets\n",
    "3. Classificació amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Anàlisis de dades\n",
    "\n",
    "El primer que haurem de fer és analitzar les dades per veure una mica com són. El que us proposem és fer una sèrie de plots per observar dades com ara:\n",
    "\n",
    "* quants tweets s'estan dirigint a una persona en concret\n",
    "* quants hastags hi ha a cada categoria de tweets\n",
    "* quants tweets hi ha de cada categoria\n",
    "* quants tweets de la categoria \"not_cyberbullying\" és dirigeixen a un usuari vs totes les altres categories\n",
    "* altres coses que penseu que poden ser rellevants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24381</th>\n",
       "      <td>Kat and Andre better fuck off this show quickl...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18709</th>\n",
       "      <td>Baat bs itni si smjhana chah rahi ki you can n...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46705</th>\n",
       "      <td>Only a nigger would say \"pause\" for my headban...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20949</th>\n",
       "      <td>Hey, Angel, you realise you said this out loud...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>RT @_dylanmills im not sexist but it seems lik...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text   cyberbullying_type\n",
       "24381  Kat and Andre better fuck off this show quickl...  other_cyberbullying\n",
       "18709  Baat bs itni si smjhana chah rahi ki you can n...             religion\n",
       "46705  Only a nigger would say \"pause\" for my headban...            ethnicity\n",
       "20949  Hey, Angel, you realise you said this out loud...             religion\n",
       "13539  RT @_dylanmills im not sexist but it seems lik...               gender"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 1:** FEU EL VOSTRE ANALISIS DE DADES AQUÍ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets que s'estan dirigint a una persona en concret: 14466\n",
      "\n",
      "Nº de hastags que hi ha a cada categoria de tweets:\n",
      "- not_cyberbullying: 1896\n",
      "- gender: 1369\n",
      "- religion: 661\n",
      "- other_cyberbullying: 794\n",
      "- age: 312\n",
      "- ethnicity: 533\n",
      "\n",
      "Nº de tweets que hi ha de cada categoria:\n",
      "- not_cyberbullying: 6357\n",
      "- gender: 6372\n",
      "- religion: 6368\n",
      "- other_cyberbullying: 6282\n",
      "- age: 6399\n",
      "- ethnicity: 6375\n",
      "\n",
      "Nº de tweets de la categoria \"not_cyberbullying\" que és dirigeixen a un usuari vs totes les altres categories:\n",
      "- 3317 vs 11149\n",
      "\n",
      "Tweets que contenen un link: 3474\n"
     ]
    }
   ],
   "source": [
    "mentions = 0\n",
    "for tweet in df_tweets_train.loc[:,\"tweet_text\"]:\n",
    "    if \"@\" in tweet:\n",
    "        mentions += 1\n",
    "print(\"Tweets que s'estan dirigint a una persona en concret:\", mentions)\n",
    "\n",
    "print(\"\\nNº de hastags que hi ha a cada categoria de tweets:\")\n",
    "for categoria in df['cyberbullying_type'].unique():\n",
    "    hastags = 0\n",
    "    for tweet in df_tweets_train.loc[df['cyberbullying_type'] == categoria,\"tweet_text\"]:\n",
    "        if \"#\" in tweet:\n",
    "            hastags += 1\n",
    "    print(\"- \" + str(categoria) + \":\", hastags)\n",
    "\n",
    "print(\"\\nNº de tweets que hi ha de cada categoria:\")\n",
    "for categoria in df['cyberbullying_type'].unique():\n",
    "    print(\"- \" + str(categoria) + \":\", len(df_tweets_train.loc[df['cyberbullying_type'] == categoria]))\n",
    "\n",
    "print('\\nNº de tweets de la categoria \"not_cyberbullying\" que és dirigeixen a un usuari vs totes les altres categories:')\n",
    "not_cyberbullying_mentions = 0\n",
    "cyberbullying_mentions= 0\n",
    "for n_tweet in range(len(df_tweets_train)):\n",
    "    if \"@\" in df_tweets_train.iloc[n_tweet].loc[\"tweet_text\"]:\n",
    "        if df_tweets_train.iloc[n_tweet].loc['cyberbullying_type'] == \"not_cyberbullying\":\n",
    "            not_cyberbullying_mentions += 1\n",
    "        else:\n",
    "            cyberbullying_mentions += 1\n",
    "print(\"-\", not_cyberbullying_mentions, \"vs\", cyberbullying_mentions)\n",
    "\n",
    "links = 0\n",
    "for tweet in df_tweets_train.loc[:,\"tweet_text\"]:\n",
    "    if \"http\" in tweet:\n",
    "        links += 1\n",
    "print(\"\\nTweets que contenen un link:\", links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar és la funció *normalize* que normalitzarà les paraules.\n",
    "\n",
    "\n",
    "No modificar la següent cel·la, s'encarrega de fer el proce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 2:** \n",
    "\n",
    "Empleneu la funció següent que, donada una paraula, la normalitzi passant tots els digits a minúscules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@memo    \n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funció que donada una paraula la normalitzi\n",
    "    Exemple: Taller DELS noUS USOS ---> tallers dels nous usos\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    # Remove punctuation and numbers, etc.\n",
    "    word = ''.join(char for char in word if char in 'abcdefghijklmnñopqrstuvwxyz ')\n",
    "    \n",
    "    #We are not sure if it would be good to erase consecutive identical characters, because people usually try to dodge\n",
    "    #obscene language filters by reapeating some letters in obscene words, and/or use it to emphasize on a word.\n",
    "    \n",
    "    #We are also not sure if it would be good to completely ignore links, accounts and hastags; since they can SOMETIMES\n",
    "    #give us a hint and help us, but IN GENERAL tend to not be that relevant.\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taller dels nous usos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"Taller DELS noUS USOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 3:** \n",
    "\n",
    "Feu una funció que construeixi un diccionari que contingui totes les paraules que s'han trobat tot indicant el total de cops que ha aparegut cadascuna i el nombre de tweets on apareix. Més a baix teniu un exemple de l'estructura que ha de tenir el output de la funció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funció que ha de construir un diccionari que contingui totes les paraules que s'han trobat indicant\n",
    "    el total de cops que ha aparegut i el nombre de tweets on apareix\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Diccionari amb el format {word : {n_ocur: valor, n_tweets: valor}, ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    word_dicc = {}\n",
    "    df_words = df.loc[:,\"tweet_text\"].str.split()\n",
    "    for tweet in df_words.index:\n",
    "        tweet_words = []\n",
    "        for word in df_words[tweet]:\n",
    "            normalized_word = normalize(word)\n",
    "            if normalized_word in tweet_words:\n",
    "                word_dicc[normalized_word]['n_ocur'] += 1\n",
    "            elif normalized_word in word_dicc:\n",
    "                word_dicc[normalized_word]['n_ocur'] += 1\n",
    "                word_dicc[normalized_word]['n_tweets'] += 1\n",
    "                tweet_words.append(normalized_word)\n",
    "            elif normalized_word != '':\n",
    "                word_dicc[normalized_word] = {'n_ocur': 1, 'n_tweets': 1}\n",
    "                tweet_words.append(normalized_word)\n",
    "    \n",
    "    return word_dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55503\n"
     ]
    }
   ],
   "source": [
    "dicc_text = count_words(df_tweets_train)\n",
    "print (len(dicc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat serà un diccionari tipus (no necessàriament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'memory' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "    'best': {'n_ocur': 123, 'n_tweets': 65},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per cada categoria de tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24381</th>\n",
       "      <td>Kat and Andre better fuck off this show quickl...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18709</th>\n",
       "      <td>Baat bs itni si smjhana chah rahi ki you can n...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46705</th>\n",
       "      <td>Only a nigger would say \"pause\" for my headban...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20949</th>\n",
       "      <td>Hey, Angel, you realise you said this out loud...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>RT @_dylanmills im not sexist but it seems lik...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text   cyberbullying_type\n",
       "24381  Kat and Andre better fuck off this show quickl...  other_cyberbullying\n",
       "18709  Baat bs itni si smjhana chah rahi ki you can n...             religion\n",
       "46705  Only a nigger would say \"pause\" for my headban...            ethnicity\n",
       "20949  Hey, Angel, you realise you said this out loud...             religion\n",
       "13539  RT @_dylanmills im not sexist but it seems lik...               gender"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 4:** \n",
    "\n",
    "Fent servir la funció que se us dona a continuació (eachTopic), apliqueu-la per tal de comptar les paraules que s'han trobat i la seva ocurrència segregant ara per categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words_categories(df):\n",
    "    \"\"\"\n",
    "    Funció que ha de constuir un diccionari que conté la freqüència de les \n",
    "    paraules i el número de tweets on ha aparegut. \n",
    "    Aquesta informació ha de ser dividida per diferents categories de cyberbullying.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Diccionari amb el format {label : {word : {n_ocur: valor, n_news: valor} } }\n",
    "    \"\"\"\n",
    "    words_topic = {}\n",
    "    \n",
    "    def eachTopic(group):\n",
    "        # Count words on this topic and save to dictionary\n",
    "        words_topic[group['cyberbullying_type'].iloc[0]] = count_words(group)\n",
    "\n",
    "    # Group by topics and apply function to each topic\n",
    "    \n",
    "    for topic in df['cyberbullying_type'].unique():\n",
    "        eachTopic(df.loc[df['cyberbullying_type'] == topic])\n",
    "    \n",
    "    return words_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "words_categories = count_words_categories(df_tweets_train)\n",
    "print (len(words_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat serà un diccionari tipus (no necessàriament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'ethnicity': {\n",
    "        'race' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "        'what': {'n_ocur': 123, 'n_tweets': 65}\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "    'gender': {\n",
    "        'jokes' : {'n_ocur': 18, 'n_tweets': 17},\n",
    "        'you': {'n_ocur': 154, 'n_tweets': 66}\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules més freqüents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de carecterístiques**\n",
    "\n",
    "L'elecció de les paraules que formen el vector de característiques és un pas crític. En funció de com de bona sigui aquesta descripció, millor funcionarà el sistema. Tot i que us deixem a vosaltres la política de creació del vector de característiques us donem una pista: per saber quines paraules fer servir una possible estratègia és agafar aquelles paraules que apareixen entre en un 10 i un 50 percent del total (sense tenir en compte la categoria). \n",
    "\n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 5:** \n",
    "\n",
    "Experimenteu omplint la llista *skip_top* amb aquelles paraules que penseu no tenen significat o relevancia per definir cada categoria. Podeu buscar informació sobre **stop words** a internet i definir varies llistes fins que penseu que obteniu una bona representació de paraules per categoria de cyberbullying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_top = (\"hi\", \"bye\", \"rt\", \"fav\", \"i\", \"ill\", \"id\", \"im\", \"ive\", \"me\", \"my\", \"myself\", \"we\", \"well\", \"wed\", \"were\", \"weve\",\n",
    "            \"our\", \"ours\", \"ourselves\", \"you\", \"u\", \"youll\", \"ull\", \"youd\", \"ud\", \"youre\", \"ure\", \"youve\", \"uve\", \"your\", \"ur\", \"yours\", \"urs\", \"yourself\", \"urself\", \"yourselves\", \"urselves\",\n",
    "            \"he\", \"hell\", \"hed\", \"hes\",\"him\", \"his\", \"himself\", \"she\", \"shell\", \"her\", \"hers\", \"herself\", \"it\", \"itll\", \"itd\",\n",
    "            \"its\", \"itself\", \"they\", \"theyll\", \"theyd\", \"theyre\", \"theyve\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\",\n",
    "            \"whats\", \"which\", \"whichs\", \"who\", \"whos\", \"whom\", \"this\", \"that\", \"thats\", \"these\", \"those\", \"am\", \"is\", \"isnt\",\n",
    "            \"are\", \"arent\", \"was\", \"wasnt\", \"werent\", \"be\", \"been\", \"being\", \"have\", \"havent\", \"has\", \"hasnt\", \"had\", \"hadnt\",\n",
    "            \"having\", \"do\", \"dont\", \"does\", \"doesnt\", \"did\", \"didnt\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\",\n",
    "            \"because\", \"cause\", \"as\", \"until\", \"til\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"bout\", \"against\",\n",
    "            \"vs\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\",\n",
    "            \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"theres\", \"therere\",\n",
    "            \"when\", \"whens\", \"where\", \"wheres\", \"why\", \"whys\", \"how\", \"hows\", \"all\", \"any\", \"both\", \"each\", \"few\", \"fews\",\n",
    "            \"more\", \"most\", \"other\", \"some\", \"such\", \"yes\", \"y\", \"no\", \"n\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\",\n",
    "            \"very\", \"can\", \"cant\", \"could\", \"couldnt\", \"will\", \"wont\", \"just\", \"should\", \"shouldnt\", \"would\", \"wouldnt\", \"now\")\n",
    "\n",
    "def topNwords(df, words, N, skip=[]):\n",
    "    \"\"\"\n",
    "    Funció que crea un diccionari amb les N paraules més representatives \n",
    "    (les que apareixen amb més freqüència) de cadascuna de les categories de cyberbullying.\n",
    "    \n",
    "    Tingueu en compte que també haureu de filtrar aquelles paraules que apareixen en la majoria \n",
    "    de tweets, així com també, les que únicament apareixen en un conjunt molt petit de tweets\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :param words: diccionari amb les paraules i la seva frequencia\n",
    "    :param N: número de paraules més representatives que volem considerar\n",
    "    :return : Diccionari amb el format {categoria1: llista_top_words_cat_1,  \n",
    "                                        categoria2: llista_top_words_cat_2, ...} \n",
    "    \"\"\"\n",
    "    top_words=dict()\n",
    "    \n",
    "    def each_word(topic, word):\n",
    "        if word not in skip:\n",
    "            return words[topic][word]['n_ocur']\n",
    "        return 0\n",
    "    \n",
    "    for topic in words:\n",
    "        top_words[topic] = sorted(words[topic], key=lambda x: each_word(topic, x))[-N:][::-1]\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = topNwords(df_tweets_train, words_categories, 20, skip_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat serà un diccionari tipus (no necessàriament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'age': ['school', 'high', ...],\n",
    "    ...\n",
    "    'religion': ['muslims', 'christian',...]\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Una pista de que aneu ben encaminats es que per cadascuna de les categories de cyberbullying obtingueu paraules rellevants per aquesta. Si no es així, vol dir que heu d'incrementar el nombre de paraules a saltar (*skip_top*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> EXPERIMENTEU AQUÍ QUÈ PASSA SEGONS LES \"STOP WORDS\" QUE USEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Característiques\n",
    "\n",
    "#### **EXERCICI 6:** \n",
    "\n",
    "Creeu el vector de característiques necessari per a fer l’entrenament del Naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funció que crea un vector de característiques necessari per a l'entrenament del classificador Naive Bayes\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :params top_words: ha de ser el diccionari que retorna topNWords\n",
    "    :return : diccionari o pd.Series que conté un np.array per a \n",
    "        cadascuna dels tweets amb el vector de característiques corresponent.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE #TODO\n",
    "    \n",
    "    return dict_feat_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_feat_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m words_categories \u001b[38;5;241m=\u001b[39m count_words_categories(df_tweets_train)\n\u001b[0;32m      3\u001b[0m top_words \u001b[38;5;241m=\u001b[39m topNwords(df_tweets_train, words_categories, N, skip_top)\n\u001b[1;32m----> 4\u001b[0m dict_feat_vector \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tweets_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_words\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mcreate_features\u001b[1;34m(df, top_words)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mFunció que crea un vector de característiques necessari per a l'entrenament del classificador Naive Bayes\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    cadascuna dels tweets amb el vector de característiques corresponent.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE #TODO\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdict_feat_vector\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_feat_vector' is not defined"
     ]
    }
   ],
   "source": [
    "N = 20 # Aquest parametre el podem canviar i fer proves per avaluar quin és el millor valor. \n",
    "words_categories = count_words_categories(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_categories, N, skip_top)\n",
    "dict_feat_vector = create_features(df_tweets_train, top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_feat_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat serà un diccionari tipus (no necessàriament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    0: np.array([0, 1, 1, 0, ...]),\n",
    "    1: np.array([0, 1, 1, 1, ...]),\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com podem observar, hi ha un vector de característiques per cadascun dels tweets en entrenament. El que esperem és que aquest vector ens estigui donant informació del que posa a cada tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Naïve Bayes\n",
    "\n",
    "Un cop tenim una representació necessitem un procés d'aprenentatge que ens permeti passar de la descripció a una categoria. \n",
    "En aquest lliurament farem servir el classificador Naïve Bayes. \n",
    "Aquest classificador forma part de la família de classificadors probabilístics. \n",
    "La sortida d'un classificador probabilístic és un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisió final correspon a la categoria amb més probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabilistics Bayesians es basen en el teorema de Bayes per realitzar els càlculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ són desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisió es simplifica a:\n",
    "$$ p(y|x) = p(y) · p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt són vàlides per la majoria de classificadors Bayesians. \n",
    "Naïve Bayes es distingeix de la resta perquè imposa una condició encara més restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleatòries. \n",
    "Naïve Bayes assumeix que totes elles són independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equació de la següent forma: La probabilitat de que el tweet descrit pel vector de característiques (0,1,0,1,1,1) sigui de la classe \"gender\" és proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"gender\" per la probabilitat que la segona paraula sí que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'últim pas que ens queda és trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representació de $0$'s i $1$'s indicant que la paraula no apareix (0) o sí apareix (1) a al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximació freqüentista a la probabilitat. \n",
    "Això vol dir que calcularem la freqüència d'aparició de cada paraula per a cada categoria. \n",
    "Aquest càlcul es fa dividint el nombre de tweets de la categoria en que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En gneral:\n",
    "$$p(x = \\text{\"school\"} | y = C)= \\frac{A}{B} $$\n",
    "on A és el número de tweets de la categoria C on hi apareix la paraula 'school' i B és el número total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts dèbils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu bé, la probabilitatpot ser 0 !!  Això vol dir, que si en el tweet no hi apareix una paraula no pot ser classificada com cap tipus de cyber bullying.\n",
    "\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una única paraula. \n",
    "Per tant, el que s'acostuma a fer és donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions es fer servir la correcció de Laplace. \n",
    "Seguint l'exemple anterior la correcció de Laplace és\n",
    "$$p(x= \\text{\"school\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M és el nombre de categories\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funció que hem de calcular en el Naive Bayes és un producte. \n",
    "El nombre de caractéristiques del vector és el nombre de termes del producte. \n",
    "Aquests nombres són iguals o menors a 1, si els multipliquem tots entre ells el resultat serà massa petit per a representar-lo en un nombre de punt flotant i el càlcul acabarà sent reduït a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logarítmica i allà operar fent servir sumes en comptes de multiplicacions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 7:** \n",
    "\n",
    "Implementeu la funció d'aprenentatge del classificador Naïve Bayes (funció **naive_bayes_learn()**). La funció ha de mostrar per pantalla el resultat obtingut \n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilizades per fer entrenament (aprenentatge). Aquest error es un valor molt optimista de com funcionarà el clasificador i mai s'ha de prendre com a mesura per comparar clasificadors. \n",
    "\n",
    "1) Programeu la funció **naive_bayes_learn** per a que estimi les probabilitats marginals condicionades.\n",
    "2) Programeu la funció **naive_bayes** que implementa el classificador. Noteu que aquesta funció está guiada i només haureu d'emplenar els espais on hem posat tres punts suspensius \"#···\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funció que estima les probabilitats marginals condicionades.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :params feats: vector de característiques de cada tweet\n",
    "    :return : probabilitats marginals condicionades\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython import embed\n",
    "def naive_bayes(df_train, feat_train, feat_test=None, df_test=None):\n",
    "    \"\"\"\n",
    "    Funció que implementa el clasificador Naive_Bayes.\n",
    "    \n",
    "    Si df_test no és None, ha de calcular l'encert sobre les dades de test. És a dir,\n",
    "    després de classificar feat_test ha de comparar la classificació amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracteristiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracteristiques de cada tweet de test\n",
    "    :param df_test: DataFrame amb els tweets que s'utilitzaran pel test\n",
    "    \n",
    "    :return : Una serie on l'index correspon amb els indexos de df_test i els valors són la\n",
    "        classificació retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    probs = naive_bayes_learn(df_train, feat_train)\n",
    "    p_of_cat = count_words_categories(df_train)\n",
    "    p_total = len(p_of_cat.keys())\n",
    "    \n",
    "    def eachFeats(row):\n",
    "        id, feat = row\n",
    "        p_max = float('-inf')\n",
    "        p_cat = 0\n",
    "\n",
    "        for category in probs:\n",
    "            # Speed up by using numpy\n",
    "            # inv is the inverse of features, 0 where 1 and 1 where 0\n",
    "            # ...\n",
    "            \n",
    "            # Probs * feats is the probability of being there, while\n",
    "            # inv - inv * feat = 1 - (0, 1, 0... inverses) * probs, probability of not being there\n",
    "            # ...\n",
    "            \n",
    "            # Sum of logs [vs] underflow caused by mul of probs\n",
    "            # ...\n",
    "\n",
    "            # Take the max, do it now to avoid extra-loops\n",
    "            # ...\n",
    "                \n",
    "        return id, p_cat\n",
    "    \n",
    "    data = map(eachFeats, feat_test.items())\n",
    "    data = pd.Series(dict(data))\n",
    "    correct = data == df_test['cyberbullying_type']\n",
    "    print(\"Accuracy: {}\".format(correct.sum() / correct.size))\n",
    "    \n",
    "    return correct.sum() / correct.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # Aquest parametre el podem canviar i fer proves per avaluar quin és el millor valor. \n",
    "words_topics = count_words_categories(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_topics, N, skip_top)\n",
    "\n",
    "feat_train = create_features(df_tweets_train, top_words)\n",
    "feat_test = create_features(df_tweets_test, top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = naive_bayes(df_tweets_train, feat_train, feat_test, df_tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haurieu d'obtenir una accuracy del 69-70%. Si heu arribat a això ja està bé! \n",
    "\n",
    "En canvi, per aquells que vulguin tenir alguns **PUNTS EXTRA**, us retem a aconseguir una accuracy més alta. A veure què podeu fer!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPLEMENTACIÓ DE MILLORA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
