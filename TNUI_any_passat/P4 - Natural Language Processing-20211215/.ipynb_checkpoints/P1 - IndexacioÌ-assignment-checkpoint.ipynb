{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Natural Language Processing o NLP és el tractament de dades textuals escrites en alguna llengua concreta. En aquesta pràctica veurem dues de les seves aplicacions: la recuperació d'informació i la classificació amb Naive Bayes.\n",
    "\n",
    "<b>Dades del Projecte Gutenberg</b>. Les dades amb les quals treballarem primer són textos de l'escriptor anglès del segle XIX Henry Rider Haggard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "\n",
    "**\\+ En les funcions, s'especifica què serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recuperació d'informació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La recuperació d'informació es preocupa pel problema que apareix quan un usuari vol cercar un document textual en una base de dades. En aquesta pràctica us donem una col·lecció de textos literaris del Projecte Gutenberg (https://www.gutenberg.org/). Com trobaríeu un llibre que contingui les paraules \"eye\", \"father\", \"work\"? Penseu en el cercador de Google: quan feu una cerca, el sistema ha de:\n",
    "\n",
    "1. Trobar documents que contenen les vostres paraules clau,\n",
    "\n",
    "2. Mostrar-vos els resultats de la cerca amb un ordre de major a menor rellevància.\n",
    "\n",
    "Sobre aquest esquema bàsic es poden fer moltes millores, com ara la cerca aproximada de text o la personalització de resultats. A més, hi pot haver moltes maneres d'ordenar els resultats. Aquí veurem una versió relativament simple del procés, i en particular només cercarem de manera exacta. Veient el següent esquema del procés de recuperació d'informació:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"60%\" src=\"img/esquema-recuperacio-informacio.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nosaltres farem les parts d'indexació, query, i sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexació\n",
    "\n",
    "La indexació consisteix en incorporar documents al nostre sistema de manera que ens resulti senzill trobar-los posteriorment. Per efectuar tal tasca, emprarem una estructura de dades anomenada **Índex Invers**. Per entendre com es fabrica, considerem una taula de documents amb algunes de les paraules que contenen: cada columna representa un document, i cada fila ens indica si aquell document conté la corresponent paraula.\n",
    "\n",
    "|          | Document 1 | Document 2 | Document 3 | Document 4 |\n",
    "|:--------:|:----------:|:----------:|:----------:|:----------:|\n",
    "| Einstein |  1         |  1         |  0         |  0         |\n",
    "|  Hubble  |  1         |  1         |  1         |  0         |\n",
    "|   Fermi  |  1         |  0         |  0         |  0         |\n",
    "|  Winfrey |  0         |  0         |  0         |  1         |\n",
    "|   Dylan  |  0         |  0         |  1         |  1         |\n",
    "\n",
    "Quins documents parlen de Hubble? Llegint la segona fila està molt clar: els tres primers. L'essència de l'índex invers es basa en cercar els termes que volem al llistat de paraules indexades, i retornar la seva \"fila\", és a dir, els documents que la contenen.\n",
    "\n",
    "A la pràctica, no podem guardar el nostre índex en una taula: tindríem un problema d'espai. A banda, necessitem una manera ràpida de cercar a la llista de paraules indexades. La cerca ràpida s'aconsegueix amb una estructura de tipus hash. Si volem una estructura de tipus hash que pugui guardar informació associada a cada terme, necessitem usar **diccionaris**. A cada terme li assignarem un conjunt (`set`) de strings, cadascuna amb l'identificador del document que pertoqui. D'aquesta manera, la taula anterior quedaria convertida en el següent diccionari:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Einstein\": {\"Document 1\", \"Document 2\"},\n",
    "    \"Hubble\": {\"Document 1\", \"Document 2\", \"Document 3\"},\n",
    "    \"Fermi\": {\"Document 1\"},\n",
    "    \"Winfrey\": {\"Document 4\"},\n",
    "    \"Dylan\": {\"Document 3\", \"Document 4\"}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per crear el vostre index invers, us proporcionem la funció `tokenize` i la classe `IndexInvers`. La funció `tokenize` és un generador que agafa un text i va treient cadascuna de les paraules que conté, de manera que podeu iterar sense haver de pensar com separar els espais i la puntuació. \n",
    "\n",
    "La classe `IndexInvers` només conté el constructor, en el qual es creen els seus atributs:\n",
    "- `tdf` (Term-document frequency): el diccionari que acabem de descriure. És del tipus `defaultdict(set)`. Això vol dir que podem accedir (i tractar amb) qualsevol clau. Si per exemple tenim la paraula \"Avui\" i la clau `tdf[\"Avui\"]` no existeix, en comptes de llençar una excepció, el `defaultdict` ens crearà la clau i aquesta contidrà un conjunt buit. \n",
    "- `doc_ids` (identificadors de document): llista on guardarem els identificadors dels documents que indexem. Serà necessari al moment de cercar a l'índex.\n",
    "\n",
    "Els identificadors consistiran en les rutes als arxius de text indexats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def tokenize(text, lowercase=True):\n",
    "    text = text.lower() if lowercase else text\n",
    "    for match in re.finditer(r\"\\w+(\\.?\\w+)*\", text):\n",
    "        yield match.group()\n",
    "\n",
    "        \n",
    "class IndexInvers:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tdf = defaultdict(set)\n",
    "        self.doc_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 1.** \n",
    "\n",
    "Implementeu la funció `index_document`, que a partir d'un índex invers, un identificador de document i un iterable de paraules, afegeixi el document a l'índex invers segons s'ha descrit al text introductori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document(inverse_index, doc_id, words):\n",
    "    \"\"\"Afegeix el document referenciat per doc_id i l'indexa d'acord amb les seves paraules. \n",
    "    Aquesta funció no ha de retornar res, només modificar els atributs de l'índex invers\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus IndexInvers\n",
    "        doc_id: string identificativa del document\n",
    "        words: objecte iterable de les paraules del document\n",
    "    \"\"\"\n",
    "    inverse_index.doc_ids.append(doc_id)\n",
    "    \n",
    "    for w in words:\n",
    "        inverse_index.tdf[w].add(doc_id) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funció `create_index` utilitza l'`index_document` que heu implementat per crear un índex invers amb els documents indicats. Executeu la següent cel·la per indexar els textos de la carpeta `haggard`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(filenames):\n",
    "    \"\"\"Crea i retorna un índex invers amb els documents d'una llista indexats.\n",
    "        \n",
    "    Input:\n",
    "        filenames: llista de documents a indexar\n",
    "        \n",
    "    Returns:\n",
    "        Un objecte de tipus IndexInvers\n",
    "    \"\"\"\n",
    "    inverse_index = IndexInvers()\n",
    "    \n",
    "    for filename in filenames:\n",
    "        index_document(inverse_index, \n",
    "                       basename(filename), \n",
    "                       tokenize(open(filename, encoding=\"utf-8\").read()))\n",
    "    \n",
    "    return inverse_index\n",
    "\n",
    "inverse_index = create_index(glob('data/haggard/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els següents tests haurien de donar `True` si heu implementat l'indexació correctament:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('The Ghost Kings 8184.txt' in inverse_index.tdf['master'])\n",
    "print('Cleopatra 2769.txt' in inverse_index.tdf['children'])\n",
    "#print(inverse_index.tdf['children'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 2.**\n",
    "\n",
    "Amb l'índex creat, ja podem fer cerques! Implementeu la funció `query` de manera que, donada una paraula clau, ens retorni tots els documents que la contenen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_one(inverse_index, term):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb el terme cercat.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndex\n",
    "        term: paraula \n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que contenen la paraula\n",
    "    \"\"\"\n",
    "    return inverse_index.tdf[term]\n",
    "        \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'She 3155.txt', 'Montezumas Daughter 1848.txt', 'She and Allan 5745.txt', 'Morning Star 2722.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'The Witchs Head (1884) 0500791.txt', 'Doctor Therne 5764.txt', 'The Brethren 2762.txt', 'Allan and the Holy Flower 5174.txt', 'Moon of Israel 2856.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Heu-Heu (1924) 0200191.txt', 'The People of the Mist 6769.txt', 'Allans Wife 2727.txt', 'Finished 1724.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'Pearl-Maiden 5175.txt', 'Swallow a tale of the great trek 4074.txt', 'The Mahatma and the Hare 2764.txt', 'The Ancient Allan 5746.txt', 'Love Eternal 3709.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Long Odds 1918.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Wanderers Necklace 3097.txt', 'Benita, an African romance 2761.txt', 'Stella Fregelius 6051.txt', 'Allan and the Ice Gods (1927) 0200201.txt', 'The Wizard 2893.txt', 'Elissa 2855.txt', 'Ayesha, the Return of She 5228.txt', 'The Virgin of the Sun 3153.txt', 'Fair Margaret 9780.txt', 'Regeneration 13434.txt', 'King Solomons Mines 2166.txt', 'Cleopatra 2769.txt', 'Jess 5898.txt', 'Dawn 10892.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Nada the Lily 1207.txt', 'Queen Shebas Ring 2602.txt', 'Red Eve 3094.txt', 'The Ivory Child 2841.txt', 'Eric Brighteyes 2721.txt', 'The Ghost Kings 8184.txt', 'The Lady of Blossholme 3813.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'The Tale of Three Lions 2729.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Allan Quatermain 711.txt', 'Black Heart and White Heart 2842.txt', 'Maiwas Revenge 2713.txt', 'Beatrice 3096.txt', 'The Worlds Desire 2763.txt', 'Child of Storm 1711.txt', 'Mr. Meesons Will 11913.txt'}\n",
      "{'She 3155.txt', 'Montezumas Daughter 1848.txt', 'She and Allan 5745.txt', 'Morning Star 2722.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'The Witchs Head (1884) 0500791.txt', 'Doctor Therne 5764.txt', 'The Brethren 2762.txt', 'Allan and the Holy Flower 5174.txt', 'Moon of Israel 2856.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Heu-Heu (1924) 0200191.txt', 'The People of the Mist 6769.txt', 'Allans Wife 2727.txt', 'Finished 1724.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'Pearl-Maiden 5175.txt', 'Swallow a tale of the great trek 4074.txt', 'The Mahatma and the Hare 2764.txt', 'The Ancient Allan 5746.txt', 'Love Eternal 3709.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Hunter Quatermains Story 2728.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Wanderers Necklace 3097.txt', 'Benita, an African romance 2761.txt', 'Stella Fregelius 6051.txt', 'Allan and the Ice Gods (1927) 0200201.txt', 'The Wizard 2893.txt', 'Elissa 2855.txt', 'Ayesha, the Return of She 5228.txt', 'The Virgin of the Sun 3153.txt', 'Fair Margaret 9780.txt', 'Regeneration 13434.txt', 'King Solomons Mines 2166.txt', 'Cleopatra 2769.txt', 'Jess 5898.txt', 'Dawn 10892.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Nada the Lily 1207.txt', 'Queen Shebas Ring 2602.txt', 'Red Eve 3094.txt', 'The Ivory Child 2841.txt', 'Eric Brighteyes 2721.txt', 'The Ghost Kings 8184.txt', 'The Lady of Blossholme 3813.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'The Tale of Three Lions 2729.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Allan Quatermain 711.txt', 'Black Heart and White Heart 2842.txt', 'Maiwas Revenge 2713.txt', 'Beatrice 3096.txt', 'The Worlds Desire 2763.txt', 'Child of Storm 1711.txt', 'Mr. Meesons Will 11913.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_one(inverse_index, \"children\"))\n",
    "print(query_one(inverse_index, \"father\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La possibilitat de fer cerques ens és útil en el moment en què podem entrar més d'un terme simultàniament. Si cerquem el text \"fa bon dia\", volem trobar els documents que continguin aquestes tres paraules (no necessàriament en aquest ordre). Dit d'una altra manera, volem la intersecció de les cerques dels termes \"fa\", \"bon\" i \"dia\".\n",
    "\n",
    "**Exercici 3.**\n",
    "\n",
    "Implementeu la funció `query_terms` de manera que donada una llista de paraules clau `*terms` ens retorni tots els documents que continguin totes les paraules clau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_terms(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb els termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndex\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que coincideixen amb la cerca.\n",
    "    \"\"\"\n",
    "    set_final = set()\n",
    "    matchproba = query_one(inverse_index,terms[0])\n",
    "    terms.remove(terms[0])\n",
    "\n",
    "    for i in terms:\n",
    "            set_final = query_one(inverse_index,i).intersection(matchproba)\n",
    "    return  set_final\n",
    "\n",
    "        \n",
    "    #return inverse_index.tdf[terms[0]] and inverse_index.tdf[terms[1]]\n",
    "    \n",
    "    \n",
    "   # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ayesha, the Return of She 5228.txt', 'Allan Quatermain 711.txt', 'The Ivory Child 2841.txt', 'Finished 1724.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_terms(inverse_index, [\"eye\", \"father\", \"work\", \"today\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 4.**\n",
    "\n",
    "Podem voler també cercar documents que continguin *alguna* de les paraules clau. Implementeu la funció `query_some_terms` per aconseguir aquest comportament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_some_terms(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb algun dels termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndexCounter\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que contenen alguna de les paraules\n",
    "    \"\"\"\n",
    "    allMatches = set()\n",
    "    # Probamos con uno primero\n",
    "    matchproba = query_one(inverse_index,terms[0])\n",
    "    terms.remove(terms[0])\n",
    "\n",
    "    # Vamos iterando el resto\n",
    "    for term in terms:\n",
    "            allMatches = query_one(inverse_index,term).union(matchproba)\n",
    "    return allMatches\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ayesha, the Return of She 5228.txt', 'Allan Quatermain 711.txt', 'The Ivory Child 2841.txt', 'Finished 1724.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_terms(inverse_index, [\"eye\", \"father\", \"work\", \"today\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Amb la funció `query_terms`, ja podem cercar qualsevol document a la nostra base de dades. Però amb això no n'hi ha prou: què passarà quan la cerca retorni massa resultats? Necessitem una manera d'ordenar els documents que apareguin a la cerca, preferiblement de més a menys rellevància.\n",
    "\n",
    "Per fer-ho, necessitem una versió modificada del nostre índex invers. Per començar, necessitem guardar la longitud de cada document. Com que cada document té un identificador, això ho podem fer directament amb un diccionari. També ho podem fer amb una estructura una mica diferent, anomenada `Counter` (https://docs.python.org/3/library/collections.html#collections.Counter).\n",
    "\n",
    "Tal com diu la documentació de `collections`, un Counter és un diccionari que ens permet comptar. Cadascun dels seus valors és només un `int`, i podem incrementar-lo sense haver de definir cada clau. Té molta similitud amb un `defaultdict(int)`. Veiem-ho amb un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gos': 3, 'gat': 2, 'gallina': 1, 'serp': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "animals = [\"gos\", \"gat\", \"gos\", \"gos\", \"gallina\", \"serp\", \"gat\"]\n",
    "for a in animals:\n",
    "    counter[a] += 1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantatge de counter és que no cal fer el bucle for! El següent codi fa exactament el mateix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gos': 3, 'gat': 2, 'gallina': 1, 'serp': 1})\n"
     ]
    }
   ],
   "source": [
    "counter2 = Counter(animals)\n",
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També disposem del mètode `most_common`, que ens dóna els n termes més comuns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gos', 3), ('gat', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(counter2.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La utilitat del `Counter` pot no estar massa clara per comptar la longitud de cada text. Hi ha una altra aplicació per la qual ens serà molt útil. Per poder ordenar els resultats de la nostra cerca, voldrem saber quantes vegades surt una paraula a cada text. Això ho podem aconseguir canviant el `tdf` del nostre índex invers (que era un `defaultdict(set)`) per un `defaultdict(Counter)`. \n",
    "\n",
    "D'aquesta manera no només sabrem quins documents contenen cada paraula, sino també la seva freqüència. Això justifica el nom TDF (Term-Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexInversCounter:\n",
    "    \"\"\"El mateix que IndexInvers, però utilitzant defaultict(Counter)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tdf = defaultdict(Counter) #key = paraula, value = counter(key = doc_id, value = cuantas veces \n",
    "                                                                            #aparece la palabra en el doc)\n",
    "        self.lengths = Counter() #afegir numero de paraules (key doc i value numero paraules -> alicia.txt, 12000)\n",
    "        self.doc_ids = [] # añadir doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 5.**\n",
    "\n",
    "Implementeu la funció `index_document_counter`, que a partir d'un índex invers `IndexInversCounter`, un identificador de document i un iterable de paraules, afegeixi el document a l'índex invers segons s'ha descrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def index_document_counter(inverse_index, doc_id, words):\n",
    "    \"\"\"Afegeix el document referenciat per doc_id i l'indexa d'acord amb les seves paraules. \n",
    "    Aquesta funció no ha de retornar res, només modificar els atributs de l'índex invers\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: string identificativa del document\n",
    "        words: objecte iterable de les paraules del document\n",
    "    \"\"\"\n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    contador = Counter(words)       \n",
    "\n",
    "    for i in contador:\n",
    "        inverse_index.tdf[i][doc_id] = contador[i]\n",
    "\n",
    "    inverse_index.lengths[doc_id] = sum(contador.values()) \n",
    "    inverse_index.doc_ids.append(doc_id)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executeu la següent cel·la per indexar els textos de la carpeta `haggard`, aquest cop amb comptatge de les longituds de cada text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counter_index(filenames):\n",
    "    \"\"\"Retorna un índex invers amb la llista d'arxius indexats.\n",
    "    \n",
    "    Input:\n",
    "        filenames: llista d'arxius\n",
    "        \n",
    "    Returns:\n",
    "        objecte del tipus IndexInversCounter\n",
    "\n",
    "    \"\"\"\n",
    "    inverse_index = IndexInversCounter()\n",
    "\n",
    "    for filename in filenames:\n",
    "        index_document_counter(inverse_index, basename(filename), tokenize(open(filename, encoding=\"utf-8\").read()))\n",
    "    \n",
    "    return inverse_index\n",
    "\n",
    "inverse_index_counter = create_counter_index(glob('data/haggard/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 6.**\n",
    "\n",
    "Ara la cerca no funcionarà, ja que estem treballant amb `Counter`s en comptes de `set`s. Modifiqueu la funció `query_terms` perquè funcioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_terms_counter(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb els termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndexCounter\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que coincideixen amb la cerca.\n",
    "    \"\"\"\n",
    "    \n",
    "    #set_final = set()\n",
    "    #set_final = inverse_index.tdf[terms[0]]\n",
    "    #matchproba = query_one(inverse_index,terms[0])\n",
    "    #terms.remove(terms[0])\n",
    "\n",
    "    #for i in terms[1]:\n",
    "       # proba = inverse_index.tdf[i]\n",
    "       # set_final = set_final.intersection(set(inverse_index.tdf[i]))\n",
    "   # return  set_final\n",
    "\n",
    "    set_final = set(inverse_index.tdf[terms[0]])    \n",
    "   \n",
    "    for i in terms[1:]:\n",
    "        actual = set(inverse_index.tdf[i])\n",
    "        set_final = set_final.intersection(actual)\n",
    "    return set_final \n",
    " \n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'She 3155.txt', 'Montezumas Daughter 1848.txt', 'She and Allan 5745.txt', 'Morning Star 2722.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'The Witchs Head (1884) 0500791.txt', 'Doctor Therne 5764.txt', 'The Brethren 2762.txt', 'Moon of Israel 2856.txt', 'The People of the Mist 6769.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Heu-Heu (1924) 0200191.txt', 'Allan and the Holy Flower 5174.txt', 'Allans Wife 2727.txt', 'Finished 1724.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'Pearl-Maiden 5175.txt', 'Swallow a tale of the great trek 4074.txt', 'The Mahatma and the Hare 2764.txt', 'The Ancient Allan 5746.txt', 'Love Eternal 3709.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Hunter Quatermains Story 2728.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Wanderers Necklace 3097.txt', 'Benita, an African romance 2761.txt', 'Stella Fregelius 6051.txt', 'Allan and the Ice Gods (1927) 0200201.txt', 'The Wizard 2893.txt', 'Elissa 2855.txt', 'Ayesha, the Return of She 5228.txt', 'The Virgin of the Sun 3153.txt', 'Fair Margaret 9780.txt', 'Regeneration 13434.txt', 'King Solomons Mines 2166.txt', 'Cleopatra 2769.txt', 'Jess 5898.txt', 'Dawn 10892.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Nada the Lily 1207.txt', 'Queen Shebas Ring 2602.txt', 'Red Eve 3094.txt', 'The Ivory Child 2841.txt', 'Eric Brighteyes 2721.txt', 'The Ghost Kings 8184.txt', 'The Lady of Blossholme 3813.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'The Tale of Three Lions 2729.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Allan Quatermain 711.txt', 'Maiwas Revenge 2713.txt', 'Beatrice 3096.txt', 'The Worlds Desire 2763.txt', 'Child of Storm 1711.txt', 'Mr. Meesons Will 11913.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_terms_counter(inverse_index_counter, [\"eye\", \"father\", \"work\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com hem esmentat, hem introduit la modificació amb `Counter` per poder tractar el problema del scoring. Hi ha diverses maneres d'ordenar els resultats de la cerca al nostre índex invers, ara en veurem dues. Quina és la manera més senzilla que se'ns ocorre per ordenar resultats?\n",
    "\n",
    "Podem ordenar els documents segons en quin d'ells apareixen més vegades les paraules que hem cercat. És a dir, si cerquem \"avui\" i en un document hi surt la paraula 10 vegades, li donarem més pes (més puntuació) que a un document on hi surti 5 vegades. D'aquesta manera, la puntuació del document $D$ al cercar els termes $q_1,\\dots,q_n$ serà\n",
    "$$\n",
    "    \\mathrm{score}_D(q_1,\\dots,d_n) = \\sum_{i=1,\\dots,n} freq(q_i,D).\n",
    "$$\n",
    "Aquesta manera de puntuar l'anomenarem \"naive\". \n",
    "\n",
    "**Exercici 7.**\n",
    "\n",
    "Implementeu la funció de puntuació naive per un document donat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_naive(inverse_index, doc_id, terms):\n",
    "    \"\"\"Puntuació naive d'un document per una cerca concreta\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: identificador del document a puntuar\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        un nombre amb la puntuació naive del document, segons la fórmula naive\n",
    "    \"\"\"    \n",
    "    puntuacio = 0\n",
    "    for i in terms:\n",
    "        puntuacio += inverse_index.tdf[i][doc_id]\n",
    "    return puntuacio\n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(score_naive(inverse_index_counter, \"The Ghost Kings 8184.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_naive(inverse_index_counter, \"The Virgin of the Sun 3153.txt\", [\"eye\", \"father\", \"work\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ràpidament ens adonem que la manera naive de puntuar pot no ser la millor. Si un document és molt més llarg que la resta, és molt mes probable que la paraula que cerquem hi aparegui freqüentment. Això li donarà una puntuació molt major que a un document més curt que pot ser més rellevant. A banda, cal tenir en compte que certes paraules (com ara els connectors i les preposicions) són massa comuns per donar informació sobre la rellevància d'un resultat de cerca.\n",
    "\n",
    "Una solució a aquests problemes ve donada pel mètode de puntuació Okapi BM25 (https://en.wikipedia.org/wiki/Okapi_BM25). Ve donat per la següent fórmula:\n",
    "\n",
    "$$\\operatorname{score}_D\\left(q_{1}, q_{2}, \\ldots, q_{n}\\right)\n",
    "=\n",
    "\\sum_{i=1}^{n} I D F\\left(q_{i}\\right) \\cdot \n",
    "\\frac{freq\\left(q_{i}, D\\right) \\cdot\\left(k_{1}+1\\right)}\n",
    "{freq\\left(q_{i}, D\\right)+k_{1} \\cdot\\left(1-b+b \\cdot \\frac{|D|}{\\operatorname{avgdl}}\\right)},$$\n",
    "on hi tenim la següent informació:\n",
    "\n",
    "- $freq(q_i, D)$ és la freqüència del terme $q_i$ al document $D$.\n",
    "- $k_1=0.75$ i $b=1.2$ són paràmetres, que es poden ajustar per donar resultats diferents.\n",
    "- $|D|$ és la longitud del document $D$.\n",
    "- $avgdl$ és la longitud mitjana de tots els documents (*av*era*g*e *d*ocument *l*ength)\n",
    "\n",
    "El terme $IDF(q_i)$ es coneix com la Inverse Document Frequency, donat per la fórmula\n",
    "$$I D F\\left(q_{i}\\right)=\\log\\left( 1+ \\frac{N-n\\left(q_{i}\\right)+0.5}{n\\left(q_{i}\\right)+0.5} \\right),$$\n",
    "on $N$ és el nombre de documents indexats, i $n(q_i)$ és el nombre de documents que contenen el terme $q_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 8.**\n",
    "\n",
    "Implementeu la fórmula de la puntuació Okapi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "k1 = 0.75\n",
    "b = 1.2\n",
    "\n",
    "def score_okapi(inverse_index, doc_id, terms):\n",
    "    \"\"\"Puntuació Okapi BM25 d'un document per una cerca concreta\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: identificador del document a puntuar\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        un nombre amb la puntuació Okapi BM25 del document, segons la fórmula descrita.\n",
    "    \"\"\"\n",
    "    puntuacio = 0    \n",
    "    for i in terms:\n",
    "        N = len(inverse_index.doc_ids)\n",
    "        n = len(inverse_index.tdf[i])\n",
    "        IDF = log(1 + (N - n + 0.5) /(n + 0.5))\n",
    "        freq = inverse_index.tdf[i][doc_id]        \n",
    "        longitud = inverse_index.lengths[doc_id]\n",
    "        mean = np.mean(list(inverse_index.lengths.values()))\n",
    "        \n",
    "    \n",
    "        puntuacio += IDF * (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * (longitud / mean )))        \n",
    "    return puntuacio   \n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.09786966124624634\n",
      "0.09755473303338251\n"
     ]
    }
   ],
   "source": [
    "print(score_okapi(inverse_index_counter, \"Hunter Quatermain's Story 2728.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_okapi(inverse_index_counter, \"The Virgin of the Sun 3153.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_okapi(inverse_index_counter, \"Nada the Lily 1207.txt\", [\"eye\", \"father\", \"work\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercici 9.**\n",
    "\n",
    "Implementeu la cerca de documents amb ordenació per puntuació. La funció `query_n` ha d'admetre un nombre arbitrari de paraules clau, un nombre de resultats màxim esperats, i una funció de puntuació a través del paràmetre `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_n(inverse_index, terms, n=10, score=score_naive):\n",
    "    \"\"\"Cerca dels n documents amb millor puntuació.\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        terms: llista de paraules\n",
    "        n: número de documents a recuperar\n",
    "        score: funció de puntuació a utilitzar\n",
    "        \n",
    "    Returns:\n",
    "        llista dels n documents amb millor puntuació, ordenats de millor a pitjor.\n",
    "    \"\"\"\n",
    "    query = query_terms_counter(inverse_index, terms)\n",
    "    resultat = sorted(query, key=lambda x: score(inverse_index, x, terms), reverse=True)\n",
    "    return resultat[:n]\n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nada the Lily 1207.txt', 'Dawn 10892.txt', 'Stella Fregelius 6051.txt', 'Regeneration 13434.txt', 'Benita, an African romance 2761.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'Love Eternal 3709.txt', 'Montezumas Daughter 1848.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt']\n"
     ]
    }
   ],
   "source": [
    "print(query_n(inverse_index_counter, [\"eye\", \"father\", \"work\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hunter Quatermains Story 2728.txt', 'The Tale of Three Lions 2729.txt', 'The Mahatma and the Hare 2764.txt', 'Maiwas Revenge 2713.txt', 'Allans Wife 2727.txt', 'King Solomons Mines 2166.txt', 'Allan and the Ice Gods (1927) 0200201.txt', 'Allan and the Holy Flower 5174.txt', 'Dawn 10892.txt', 'Lysbeth, a Tale of the Dutch 5754.txt']\n"
     ]
    }
   ],
   "source": [
    "print(query_n(inverse_index_counter, [\"eye\", \"father\", \"work\"], score=score_okapi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
